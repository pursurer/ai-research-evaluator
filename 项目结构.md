# AI 研究方向自动评估系统 - 项目结构

## 代码库指南 (Repo Orientation)

本项目采用 **Python 单体仓库**设计，核心功能模块化，便于扩展和维护。

### 技术栈
| 层级 | 技术选型 | 说明 |
|------|---------|------|
| **语言** | Python 3.10+ | 主开发语言 |
| **包管理** | Poetry / pip | 依赖管理 |
| **LLM 接口** | LangChain / 原生 API | 抽象层，支持多提供商 |
| **数据处理** | Pandas | CSV 解析与统计 |
| **配置管理** | python-dotenv + YAML | 环境变量 + 配置文件 |
| **CI/CD** | GitHub Actions | 自动化任务 |
| **测试** | pytest | 单元测试与集成测试 |

---

## 文件结构 (File Structure)

```
ai-research-evaluator/                    # GitHub 独立仓库根目录
│
├── README.md                             # 项目说明（含未来模块预告）
├── LICENSE                               # 开源协议
├── pyproject.toml                        # Poetry 依赖配置
├── requirements.txt                      # pip 依赖（备选）
├── .env.example                          # 环境变量模板
├── .gitignore                            # Git 忽略规则
│
├── config/                               # 配置文件目录
│   ├── settings.yaml                     # 全局配置（数据路径、输出格式等）
│   ├── llm_config.yaml                   # LLM 提供商配置
│   └── evaluation_weights.yaml           # P-F-C 权重与阈值配置
│
├── src/                                  # 核心源代码
│   ├── __init__.py
│   │
│   ├── data/                             # 数据加载与处理模块
│   │   ├── __init__.py
│   │   ├── loader.py                     # CSV 数据加载器
│   │   ├── cleaner.py                    # 数据清洗逻辑
│   │   ├── schema.py                     # 数据模型定义 (Pydantic)
│   │   └── trend_analyzer.py             # 关键词趋势统计
│   │
│   ├── evaluation/                       # P-F-C 评估引擎
│   │   ├── __init__.py
│   │   ├── engine.py                     # 评估主引擎
│   │   ├── potential.py                  # P 维度评估 (P1, P2, P3)
│   │   ├── feasibility.py                # F 维度评估 (F1, F2, F3)
│   │   ├── competition.py                # C 维度评估 (C1, C2)
│   │   ├── scorer.py                     # ROI 综合评分计算
│   │   └── prompts/                      # LLM Prompt 模板
│   │       ├── potential_prompts.py
│   │       ├── feasibility_prompts.py
│   │       └── competition_prompts.py
│   │
│   ├── llm/                              # LLM 抽象层
│   │   ├── __init__.py
│   │   ├── base.py                       # 抽象基类
│   │   ├── openai_client.py              # OpenAI 实现
│   │   ├── anthropic_client.py           # Claude 实现
│   │   ├── local_client.py               # 本地模型实现 (Ollama等)
│   │   └── factory.py                    # 客户端工厂
│   │
│   ├── report/                           # 报告生成模块
│   │   ├── __init__.py
│   │   ├── generator.py                  # Markdown 报告生成器
│   │   ├── templates/                    # 报告模板
│   │   │   ├── full_report.md.j2         # 完整报告模板 (Jinja2)
│   │   │   ├── summary.md.j2             # 摘要模板
│   │   │   └── comparison.md.j2          # 多方向对比模板
│   │   └── charts.py                     # 图表生成 (ASCII/Mermaid)
│   │
│   ├── discovery/                        # 研究方向自动发现 [阶段二]
│   │   ├── __init__.py
│   │   ├── hotspot_detector.py           # 热点检测算法
│   │   └── recommender.py                # 方向推荐器
│   │
│   ├── intelligence/                     # 动态情报模块 [未来模块]
│   │   ├── __init__.py
│   │   ├── twitter_monitor.py            # X (Twitter) 爬虫
│   │   ├── blog_rss.py                   # 官方 Blog RSS 解析
│   │   ├── arxiv_tracker.py              # arXiv 追踪
│   │   └── entity_alignment.py           # 实体对齐引擎
│   │
│   ├── external_api/                     # 外部 API 集成 [未来模块]
│   │   ├── __init__.py
│   │   ├── semantic_scholar.py           # 引用数据 API
│   │   ├── papers_with_code.py           # SOTA 榜单 API
│   │   └── google_trends.py              # 趋势数据 API
│   │
│   └── utils/                            # 通用工具
│       ├── __init__.py
│       ├── logger.py                     # 日志配置
│       ├── exceptions.py                 # 自定义异常
│       └── helpers.py                    # 辅助函数
│
├── tests/                                # 测试目录
│   ├── __init__.py
│   ├── conftest.py                       # pytest 配置与 fixtures
│   ├── test_data/                        # 测试数据样本
│   │   └── sample_papers.csv
│   ├── test_loader.py
│   ├── test_evaluation.py
│   ├── test_report.py
│   └── test_llm.py
│
├── scripts/                              # 运行脚本
│   ├── evaluate.py                       # 主入口：评估指定研究方向
│   ├── discover.py                       # 自动发现热点方向
│   ├── batch_evaluate.py                 # 批量评估多个方向
│   └── sync_reports.py                   # GitHub 报告同步
│
├── reports/                              # 生成的报告目录
│   └── YYYY-MM/                          # 按年月归档
│       ├── video_generation.md
│       ├── rag_retrieval.md
│       └── monthly_summary.md
│
├── data/                                 # 本地数据副本（可选）
│   └── .gitkeep                          # 实际数据通过配置指向外部路径
│
└── .github/                              # GitHub 配置
    └── workflows/
        ├── weekly_evaluation.yml         # 每周定时评估
        ├── manual_trigger.yml            # 手动触发工作流
        └── tests.yml                     # CI 测试
```

---

## 设置与环境 (Setup and Environment)

### 环境变量 (.env)
```bash
# LLM 配置 (用户自选)
LLM_PROVIDER=openai                       # openai / anthropic / local
OPENAI_API_KEY=sk-xxx                     # OpenAI API Key
ANTHROPIC_API_KEY=sk-ant-xxx              # Anthropic API Key
LOCAL_MODEL_ENDPOINT=http://localhost:11434  # Ollama 等本地模型

# 数据路径
PAPERS_DATA_ROOT=/Users/xxx/论文系统/顶会论文信息

# GitHub (用于自动同步)
GITHUB_TOKEN=ghp_xxx
GITHUB_REPO=username/ai-research-evaluator

# 可选：外部 API [未来模块]
SEMANTIC_SCHOLAR_API_KEY=
TWITTER_BEARER_TOKEN=
```

### 配置文件 (config/settings.yaml)
```yaml
# 全局设置
project:
  name: "AI Research Direction Evaluator"
  version: "0.1.0"
  language: ["zh", "en"]  # 双语支持

# 数据源配置
data_sources:
  conferences:
    - name: NeurIPS
      path: "${PAPERS_DATA_ROOT}/NeurIPS/neurips_papers.csv"
    - name: ICLR
      path: "${PAPERS_DATA_ROOT}/ICLR/iclr_papers.csv"
    # ... 其他顶会

# 输出配置
output:
  report_dir: "./reports"
  format: "markdown"
  archive_pattern: "YYYY-MM"
```

### 安装步骤
```bash
# 1. 克隆仓库
git clone https://github.com/username/ai-research-evaluator.git
cd ai-research-evaluator

# 2. 创建虚拟环境
python -m venv venv
source venv/bin/activate  # macOS/Linux

# 3. 安装依赖
pip install -r requirements.txt
# 或使用 Poetry
poetry install

# 4. 配置环境变量
cp .env.example .env
# 编辑 .env 填入必要的 API Key

# 5. 运行测试
pytest

# 6. 执行评估
python scripts/evaluate.py --direction "Video Generation"
```

---

## 代码风格 (Code Style)

| 规范 | 工具 | 配置 |
|------|------|------|
| 代码格式化 | Black | `line-length = 100` |
| 导入排序 | isort | `profile = "black"` |
| 类型检查 | mypy | `strict = true` |
| 代码检查 | ruff | 替代 flake8 |
| 文档字符串 | Google Style | 中英双语注释 |

### 命名约定
- **文件名**: snake_case (`trend_analyzer.py`)
- **类名**: PascalCase (`EvaluationEngine`)
- **函数/变量**: snake_case (`calculate_roi_score`)
- **常量**: UPPER_SNAKE_CASE (`DEFAULT_THRESHOLD`)

---

## API 与契约 (APIs and Contracts)

### 核心接口定义

#### 1. 评估引擎接口
```python
class EvaluationEngine:
    """研究方向评估核心引擎"""
    
    def evaluate(
        self, 
        direction: str,           # 研究方向名称/关键词
        context: Optional[str],   # 补充描述（可选）
        user_constraints: Optional[Dict]  # 用户约束（如算力限制）
    ) -> EvaluationResult:
        """
        执行完整的 P-F-C 评估
        
        Returns:
            EvaluationResult: 包含各维度评分、综合分数、决策建议
        """
        pass
```

#### 2. 数据模型
```python
from pydantic import BaseModel
from typing import List, Optional
from enum import Enum

class DecisionLevel(Enum):
    STRATEGIC_FOCUS = "战略重点"      # S >= 7.0
    OPPORTUNITY = "差异化突围"         # 5.5 <= S < 7.0, P_avg > 8
    QUICK_WINS = "快速捡漏"           # 5.5 <= S < 7.0, F_min > 8
    AVOID = "审慎避开"                # S < 5.5 或熔断

class DimensionScore(BaseModel):
    score: float                      # 1-10 分
    analysis: str                     # 分析说明
    evidence: List[str]               # 支撑证据

class EvaluationResult(BaseModel):
    direction: str                    # 研究方向
    timestamp: str                    # 评估时间
    
    # P 维度
    p1_trend: DimensionScore          # 趋势红利
    p2_narrative: DimensionScore      # 叙事深度
    p3_sota: DimensionScore           # SOTA 渗透率
    p_avg: float                      # P 平均分
    
    # F 维度
    f1_compute: DimensionScore        # 算力匹配度
    f2_data: DimensionScore           # 数据获取
    f3_iteration: DimensionScore      # 迭代周期
    f_min: float                      # F 最小值（短板）
    
    # C 维度
    c1_avoidance: DimensionScore      # 巨头避让度
    c2_gap: DimensionScore            # 研究空白区
    c_avg: float                      # C 平均分
    
    # 综合结果
    roi_score: float                  # 综合 ROI 分数
    fuse_triggered: bool              # 是否触发熔断
    decision: DecisionLevel           # 决策建议
    prediction_6_12_months: str       # 6-12 月预测
    risks: List[str]                  # 潜在风险
```

#### 3. LLM 抽象接口
```python
from abc import ABC, abstractmethod

class BaseLLMClient(ABC):
    """LLM 客户端抽象基类"""
    
    @abstractmethod
    def complete(
        self, 
        prompt: str, 
        system_prompt: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: int = 2000
    ) -> str:
        """执行单次补全"""
        pass
    
    @abstractmethod
    def structured_output(
        self, 
        prompt: str,
        output_schema: Type[BaseModel]
    ) -> BaseModel:
        """返回结构化输出"""
        pass
```

---

## 访问模式 (Access Patterns)

### 命令行使用
```bash
# 评估单个方向
python scripts/evaluate.py --direction "RAG Retrieval Augmented Generation"

# 评估并指定用户约束
python scripts/evaluate.py --direction "Video Generation" \
    --compute-budget "single-4090" \
    --output "./reports/2024-12/video_gen.md"

# 自动发现热点
python scripts/discover.py --top-k 10 --min-growth-rate 0.5

# 批量评估
python scripts/batch_evaluate.py --input directions.txt --parallel 4
```

### Python API 使用
```python
from src.evaluation import EvaluationEngine
from src.llm import LLMClientFactory
from src.data import PapersLoader

# 初始化
llm = LLMClientFactory.create("openai")
loader = PapersLoader(config_path="config/settings.yaml")
engine = EvaluationEngine(llm=llm, data_loader=loader)

# 执行评估
result = engine.evaluate(
    direction="Multimodal Alignment",
    user_constraints={"compute": "8xA100"}
)

# 生成报告
from src.report import ReportGenerator
report = ReportGenerator()
markdown = report.generate(result, language="zh")
```

---

## 错误处理机制 (Error Handling)

### 自定义异常
```python
# src/utils/exceptions.py

class EvaluatorException(Exception):
    """基础异常类"""
    pass

class DataLoadError(EvaluatorException):
    """数据加载失败"""
    pass

class LLMAPIError(EvaluatorException):
    """LLM API 调用失败"""
    def __init__(self, provider: str, message: str, retry_after: int = None):
        self.provider = provider
        self.retry_after = retry_after
        super().__init__(f"[{provider}] {message}")

class ConfigurationError(EvaluatorException):
    """配置错误"""
    pass

class FuseTriggerError(EvaluatorException):
    """熔断触发（F_min < 3）"""
    def __init__(self, direction: str, f_min: float):
        super().__init__(f"Direction '{direction}' fused: F_min={f_min} < 3")
```

### 重试策略
```python
# LLM API 调用重试
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=60)
)
def call_llm_with_retry(client, prompt):
    return client.complete(prompt)
```

---

## 扩展性设计 (Extensibility)

### 新增顶会数据集
1. 将 CSV 文件放入对应目录
2. 在 `config/settings.yaml` 中添加配置：
```yaml
data_sources:
  conferences:
    - name: CVPR  # 新增
      path: "${PAPERS_DATA_ROOT}/CVPR/cvpr_papers.csv"
```

### 新增 LLM 提供商
1. 继承 `BaseLLMClient` 实现新客户端
2. 在 `LLMClientFactory` 中注册

### 新增动态情报源
1. 在 `src/intelligence/` 下创建新模块
2. 实现统一的 `IntelligenceSource` 接口

