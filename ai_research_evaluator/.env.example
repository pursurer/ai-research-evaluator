# ============================================
# AI Research Evaluator - Environment Variables
# ============================================
# Copy this file to .env and fill in your values
# cp .env.example .env

# --------------------------------------------
# LLM Configuration (Required)
# --------------------------------------------
# Choose your LLM provider: openai / anthropic / local
LLM_PROVIDER=openai

# OpenAI API Key (if using OpenAI)
OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic API Key (if using Claude)
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# Local model endpoint (if using Ollama or similar)
LOCAL_MODEL_ENDPOINT=http://localhost:11434
LOCAL_MODEL_NAME=llama3

# --------------------------------------------
# Data Configuration (Required)
# --------------------------------------------
# Path to the conference papers data directory
# Should contain subdirectories like NeurIPS/, ICLR/, etc.
PAPERS_DATA_ROOT=/path/to/顶会论文信息

# --------------------------------------------
# GitHub Configuration (Optional)
# --------------------------------------------
# For automatic report synchronization
GITHUB_TOKEN=ghp_your-github-token-here
GITHUB_REPO=username/ai-research-evaluator

# --------------------------------------------
# External APIs (Future Modules)
# --------------------------------------------
# Semantic Scholar API Key (optional, for citation data)
SEMANTIC_SCHOLAR_API_KEY=

# Twitter/X Bearer Token (optional, for social monitoring)
TWITTER_BEARER_TOKEN=

# --------------------------------------------
# Application Settings
# --------------------------------------------
# Log level: DEBUG / INFO / WARNING / ERROR
LOG_LEVEL=INFO

# Output language: zh / en / both
OUTPUT_LANGUAGE=both
